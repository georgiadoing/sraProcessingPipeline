{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "1. Only works for single SRR files right now. Need to work through the logic statement maze and fix things for multiple SRR files to a single Sample\n",
    "2. Quality checks\n",
    "\n",
    "We're using os and glob to do bash script stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#stores the working directory as a string\n",
    "path = os.getcwd()\n",
    "\n",
    "#ref folder name, ref genomes go here\n",
    "ref_folder = 'references'\n",
    "\n",
    "#data folder name, samples and runs go here\n",
    "data = 'data'\n",
    "\n",
    "#csv output folder name\n",
    "csv = 'Ex'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of SRR#s to Automate Downloading Data\n",
    "\n",
    "Use Georgia's metadata table to download sample runs. \n",
    "\n",
    "Metadata Table -> dataframe -> list of SRR#s (or SRR#s paired to biosample/experiment)\n",
    "\n",
    "List of SRR#s -> SRA Toolkit -> fastq files -> salmon -> quant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in SRR#s from metadata table provided by Georgia\n",
    "sra_run_table = pd.read_csv(r'SraRunTable.csv', sep=\",\", header=0, index_col=0)\n",
    "#print(sra_run_table['Run'][3:7])\n",
    "\n",
    "#create a dict key of biosamples : srr numbers(could do SRX:SRR instead)\n",
    "bio_sample_dic = sra_run_table.groupby('BioSample').agg({'Run':lambda x:x.tolist()})['Run'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Index\n",
    "Use salmon to build index. Download genomes from ensemble and store in refences folder. Will align to references in parallel. This is written to align to as many reference genomes/transcriptomes as are put in the references folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs stuff and returns a list of them-used throughout\n",
    "def grab_ref(ref_folder1):\n",
    "    files=glob.glob(ref_folder1+'/*')\n",
    "    #print(files)\n",
    "    return(files)\n",
    "\n",
    "#builds Salmon index from given file names, puts indexes into folder, INDEX_references \n",
    "def salmon_index(genome):\n",
    "    #os.system('salmon index -t '+str(genome)+' -i INDEX_'+str(genome))\n",
    "    #print('salmon '+ genome)\n",
    "    return \n",
    "\n",
    "#call grab_ref() and salmon_index() to build index for each reference genome\n",
    "for i in grab_ref(ref_folder):\n",
    "    salmon_index(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Quants for Each Reference Genome on a Per Sample Basis\n",
    "We want all of the runs from each sample to be fed into salmon at one time. This is currently robust to number of runs and paired vs unpaired, salmon determines library type automatically. Salmon says run files must be of same library type and aligned to same transcriptome. \n",
    "\n",
    "loops through indexes and samples (SRR#, biosample, experiment? - need to sort this out) and runs quant for each sample and each index. \n",
    "\n",
    "fastqdump downloads data on the fly so we are not running prefetch\n",
    "\n",
    "still need to test this robustly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: Pseudomonas_aeruginosa_UCBPP-PA14_109\n",
      "Quant output:quants/Pseudomonas_aeruginosa_UCBPP-PA14_109/SAMN02691047_quant\n",
      "Multiple Folder Case\n",
      "Multiple runs for data/SAMN02691047/SRR2099907\n",
      "Multiple paired runs for SAMN02691047\n",
      "Multiple runs for data/SAMN02691047/SRR2098932\n",
      "Multiple paired runs for SAMN02691047\n",
      "Multiple runs for data/SAMN02691047/SRR2098784\n",
      "Multiple paired runs for SAMN02691047\n",
      "Salmon Input: -1 data/SAMN02691047/SRR2099907/SRR2099907_1.fastq.gz data/SAMN02691047/SRR2098932/SRR2098932_1.fastq.gz data/SAMN02691047/SRR2098784/SRR2098784_1.fastq.gz -2 data/SAMN02691047/SRR2099907/SRR2099907_2.fastq.gz data/SAMN02691047/SRR2098932/SRR2098932_2.fastq.gz data/SAMN02691047/SRR2098784/SRR2098784_2.fastq.gz\n",
      "Index: Pseudomonas_aeruginosa_PAO1_107\n",
      "Quant output:quants/Pseudomonas_aeruginosa_PAO1_107/SAMN02691047_quant\n",
      "Multiple Folder Case\n",
      "Multiple runs for data/SAMN02691047/SRR2099907\n",
      "Multiple paired runs for SAMN02691047\n",
      "Multiple runs for data/SAMN02691047/SRR2098932\n",
      "Multiple paired runs for SAMN02691047\n",
      "Multiple runs for data/SAMN02691047/SRR2098784\n",
      "Multiple paired runs for SAMN02691047\n",
      "Salmon Input: -1 data/SAMN02691047/SRR2099907/SRR2099907_1.fastq.gz data/SAMN02691047/SRR2098932/SRR2098932_1.fastq.gz data/SAMN02691047/SRR2098784/SRR2098784_1.fastq.gz -2 data/SAMN02691047/SRR2099907/SRR2099907_2.fastq.gz data/SAMN02691047/SRR2098932/SRR2098932_2.fastq.gz data/SAMN02691047/SRR2098784/SRR2098784_2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "index_names =[] #will use this later\n",
    "\n",
    "for y in glob.glob('INDEX_'+ref_folder+'/*'):\n",
    "    index_name = y.replace('INDEX_references/','').replace('.ffn.gz','')\n",
    "    print('Index: '+index_name)\n",
    "    index_names.append(index_name)\n",
    "    #you could fairly easily change this to loop by experiment \n",
    "    #number or biosample number...need to talk about which one to choose\n",
    "    for w in list(bio_sample_dic.keys())[601:602]:\n",
    "        for q in bio_sample_dic[w]:\n",
    "            dump_directory = 'data/'+w+'/'+q\n",
    "            #os.system('mkdir data/'+w+'/'+q)\n",
    "            #print('Dump Directory: '+dump_directory)\n",
    "            #os.system('fastq-dump --outdir '+dump_directory+' -v --gzip --skip-technical --readids --split-3 --clip '+q)\n",
    "        run_folders = grab_ref('data/'+w)\n",
    "        output_name='quants/'+index_name+'/'+w+'_quant'\n",
    "        print('Quant output:'+output_name)\n",
    "        if len(run_folders)<1:\n",
    "            print('Oops, no runs for '+w)\n",
    "        if len(run_folders)==1:\n",
    "            if len(grab_ref(run_folders[0]))<1:\n",
    "                print('Oops, no runs for '+w)\n",
    "            elif len(grab_ref(run_folders[0]))==1:\n",
    "                print('One run for ')\n",
    "                print('Salmon input: '+grab_ref(run_folders[0])[0])\n",
    "                #os.system('salmon quant -i '+y+' -l A '+grab_ref(run_folders[0])[0]+' -p 8 --validateMappings -o '+output_name)\n",
    "            elif len(grab_ref(run_folders[0]))>1:\n",
    "                runs = grab_ref(run_folders[0])\n",
    "                print('Multiple runs for ')\n",
    "                if \"_1\" in runs[0] or \"_2\" in runs[0]:\n",
    "                    print('Multiple paired runs for '+w)\n",
    "                    input_name='-1'\n",
    "                    for z in np.arange(0, len(runs)):\n",
    "                        if \"_1\" in runs[z]:\n",
    "                            input_name+= ' '+runs[z]\n",
    "                    input_name+=' -2'\n",
    "                    for z in np.arange(0, len(runs)):\n",
    "                        if \"_2\" in runs[z]:\n",
    "                            input_name+= ' '+runs[z]\n",
    "                else:\n",
    "                    print('Multiple runs for '+z)\n",
    "                    input_name='-r'\n",
    "                    for z in np.arange(0, len(runs)):\n",
    "                        input_name+= ' '+runs[z]\n",
    "                print('Salmon Input: '+input_name)\n",
    "        if len(run_folders)>1:\n",
    "            print('Multiple Folder Case')\n",
    "            first_read_str = ''\n",
    "            second_read_str = ''\n",
    "            orphan_read = '-r'\n",
    "            for run_folder in run_folders:\n",
    "                if len(grab_ref(run_folder))<1:\n",
    "                    print('Opps, no runs for '+run_folder)\n",
    "                elif len(grab_ref(run_folder))==1:\n",
    "                    print('One run for '+run_folder)\n",
    "                    print('Salmon input: '+grab_ref(run_folder)[0])\n",
    "                    orphan_read += ' '+grab_ref(run_folder)[0]\n",
    "                    #os.system('salmon quant -i '+y+' -l A '+grab_ref(run_folders[0])[0]+' -p 8 --validateMappings -o '+output_name)\n",
    "                elif len(grab_ref(run_folder))>1:\n",
    "                    print('Multiple runs for '+run_folder)\n",
    "                    runs=grab_ref(run_folder)\n",
    "                    if \"_1\" in runs[0] or \"_2\" in runs[0]:\n",
    "                        print('Multiple paired runs for '+w)\n",
    "                        for z in np.arange(0, len(runs)):\n",
    "                            if \"_1\" in runs[z]:\n",
    "                                first_read_str += ' '+runs[z]\n",
    "                        for z in np.arange(0, len(runs)):\n",
    "                            if \"_2\" in runs[z]:\n",
    "                                second_read_str+= ' '+runs[z]\n",
    "                    else:\n",
    "                        print('Multiple runs for '+run_folder)\n",
    "                        for z in np.arange(0, len(runs)):\n",
    "                            orphan_read+=runs[z]\n",
    "            if len(orphan_read) > 2: \n",
    "                if len(first_read_str)>1 or len(second_read_str)>1:\n",
    "                    input_name = orphan_read+first_read_str+second_read_Str\n",
    "                else: \n",
    "                    input_name = orphan_read\n",
    "            elif len(orphan_read) == 2:\n",
    "                input_name = '-1'+first_read_str+' -2'+second_read_str\n",
    "            print('Salmon Input: '+input_name)\n",
    "            os.system('salmon quant -i '+y+' -l A '+input_name+' -p 8 --validateMappings -o '+output_name)\n",
    "            #os.system('rm -r data/'+w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Output\n",
    "\n",
    "Copied Alex's code. \n",
    "\n",
    "Similar to running the quants, for each reference genome, we're going to grab the quants on a sample by sample basis and construct a data frame for each reference genome. The dataframes will be stored in a list. \n",
    "\n",
    "Not sure if row names are robust. I think they are, but I have not thought hard about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Name                    PGD1650835  PGD1650837  PGD1650839  PGD1650841  \\\n",
      "GD9-45172138_pstB_rep2   81.384071  138.613259   54.629463   60.874352   \n",
      "GD1-45169164-WT_rep1    127.575897  219.302219   91.260433   91.858371   \n",
      "GD3-45171150-pstB_rep1   91.179014  135.601506   63.020443   68.330303   \n",
      "GD7-45169169_WT_rep2    116.865091  193.588654   74.004411   76.063677   \n",
      "\n",
      "Name                    PGD1650843  PGD1650845  PGD1650847  PGD1650849  \\\n",
      "GD9-45172138_pstB_rep2   16.263993   20.311225  291.508020   16.548822   \n",
      "GD1-45169164-WT_rep1     34.162917   38.739507  330.823388   27.026849   \n",
      "GD3-45171150-pstB_rep1   19.360923   33.289960  239.189432   18.592331   \n",
      "GD7-45169169_WT_rep2     28.681000   27.889116  260.181345   25.425216   \n",
      "\n",
      "Name                    PGD1650851  PGD1650853  ...  PGD1662756  PGD1662758  \\\n",
      "GD9-45172138_pstB_rep2   24.734659   16.689345  ...   59.918662   70.914933   \n",
      "GD1-45169164-WT_rep1     37.421190   28.794584  ...  112.652261  135.126782   \n",
      "GD3-45171150-pstB_rep1   28.412282   16.646756  ...   65.701431   94.854448   \n",
      "GD7-45169169_WT_rep2     37.347570   20.823225  ...  105.295409  136.485155   \n",
      "\n",
      "Name                    PGD1662760  PGD1662762  PGD1662764  PGD1662766  \\\n",
      "GD9-45172138_pstB_rep2   67.140861   81.623421   70.490509   87.711450   \n",
      "GD1-45169164-WT_rep1    114.238909  138.301991  127.870066  149.247151   \n",
      "GD3-45171150-pstB_rep1   68.569647   89.682203   83.865981   93.840525   \n",
      "GD7-45169169_WT_rep2    103.562064  127.770146  118.138339  145.280452   \n",
      "\n",
      "Name                    PGD1662768  PGD1662770  PGD1662772  PGD1662774  \n",
      "GD9-45172138_pstB_rep2    2.765635   17.087963   26.701932  416.686346  \n",
      "GD1-45169164-WT_rep1      1.063876   32.569334   48.189755  675.424271  \n",
      "GD3-45171150-pstB_rep1    6.780009   19.274641   28.239186  458.536703  \n",
      "GD7-45169169_WT_rep2      2.446765   27.869981   43.361886  631.812119  \n",
      "\n",
      "[4 rows x 5959 columns], Name                     PGD134012   PGD134018  PGD134020  PGD134022  \\\n",
      "GD9-45172138_pstB_rep2   71.834936  124.675340  48.269022  54.192599   \n",
      "GD1-45169164-WT_rep1    107.471927  188.848094  74.650070  78.462130   \n",
      "GD3-45171150-pstB_rep1   76.439793  116.161652  53.025136  58.507142   \n",
      "GD7-45169169_WT_rep2     98.688823  164.055766  61.400547  65.038427   \n",
      "\n",
      "Name                    PGD134024  PGD134014   PGD134016  PGD134026  \\\n",
      "GD9-45172138_pstB_rep2  14.214452  17.656987  257.865321  14.765938   \n",
      "GD1-45169164-WT_rep1    29.484523  32.789042  283.338620  22.703028   \n",
      "GD3-45171150-pstB_rep1  16.580511  28.830020  201.370570  15.446952   \n",
      "GD7-45169169_WT_rep2    24.940631  24.590215  218.602939  21.357555   \n",
      "\n",
      "Name                    PGD134030  PGD134032  ...   PGD133904  PGD133906  \\\n",
      "GD9-45172138_pstB_rep2  21.899783  13.832596  ...   63.848350  58.422080   \n",
      "GD1-45169164-WT_rep1    32.513527  24.039219  ...  122.045109  96.064462   \n",
      "GD3-45171150-pstB_rep1  23.930603  13.696123  ...   76.855795  56.996362   \n",
      "GD7-45169169_WT_rep2    31.978137  17.469902  ...  115.300745  87.731945   \n",
      "\n",
      "Name                     PGD133902   PGD133898   PGD133900  PGD133894  \\\n",
      "GD9-45172138_pstB_rep2   72.221004   61.250208   78.447117   2.165411   \n",
      "GD1-45169164-WT_rep1    115.967914  111.900840  127.295546   0.543062   \n",
      "GD3-45171150-pstB_rep1   76.277523   71.307640   80.161277   4.284620   \n",
      "GD7-45169169_WT_rep2    109.315456   98.678919  123.742567   2.183937   \n",
      "\n",
      "Name                    PGD133896  PGD133892   PGD133884    PGD133886  \n",
      "GD9-45172138_pstB_rep2  15.210446  24.083117  276.748996   914.812558  \n",
      "GD1-45169164-WT_rep1    28.071195  40.860817  489.691585  1399.002274  \n",
      "GD3-45171150-pstB_rep1  15.882061  24.981668  329.199404  1478.250392  \n",
      "GD7-45169169_WT_rep2    22.847828  36.710528  415.285782  1677.359230  \n",
      "\n",
      "[4 rows x 5687 columns]]\n"
     ]
    }
   ],
   "source": [
    "#loop through indexes and build dataframe of output for each one\n",
    "df_list = []\n",
    "for i in index_names:\n",
    "    glob_list = []\n",
    "    replace = 'quants/'+i+'/'\n",
    "    #print(i)\n",
    "    for z in grab_ref('quants/'+i):\n",
    "        #print(z)\n",
    "        for file in glob.glob(z+'/*.sf'):\n",
    "            glob_list.append(file)\n",
    "            #print(file)\n",
    "    expression_df = pd.DataFrame(\n",
    "    pd.read_csv(file, sep=\"\\t\", index_col=0)[\"TPM\"].\n",
    "        rename(file.replace(replace, '').replace('_quant/quant.sf',''))\n",
    "    for file in glob_list)\n",
    "    df_list.append(expression_df)\n",
    "    expression_df.to_csv(csv+'/aligned_to_'+i, sep='\\t')\n",
    "print(df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
